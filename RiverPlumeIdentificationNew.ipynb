{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqgdrV7tWGrMxDFa+a2iUd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mluppichini/CleverRiver/blob/main/RiverPlumeIdentificationNew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Configuration of Google Earth Engine\n",
        "\n",
        "Execute the code to import the GEE libraries and then follow the Google procedure to configure correctly the API"
      ],
      "metadata": {
        "id": "igrTENDrqpip"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JZxEI0mi4_cX"
      },
      "outputs": [],
      "source": [
        "#@markdown Execute the Step 1 - Configuration Google Earth Engine\n",
        "\n",
        "import ee\n",
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize(project=\"buoyant-site-331313\")\n",
        "\n",
        "import pandas as pd\n",
        "import keras\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Import the python function and libraries\n",
        "\n",
        "Execute the code to import the libraries and function used in this workflow.\n",
        "Then this procedure import the data (see support material) into the \"Support\" folder"
      ],
      "metadata": {
        "id": "1YKVXCZirRLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Execute the Step 2 - Import Functions and Libraries\n",
        "\n",
        "from osgeo import gdal,osr\n",
        "from osgeo.gdalconst import GDT_Float32\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "import geopandas as gp\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "try:\n",
        "  os.mkdir(\"./Support\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "def LatLonImg(img, col, area, scale, NDSSI = False):\n",
        "    img = img.addBands(ee.Image.pixelLonLat())\n",
        "\n",
        "    img = img.reduceRegion(reducer=ee.Reducer.toList(), \\\n",
        "                           geometry=area, \\\n",
        "                           maxPixels=1e13, \\\n",
        "                           scale=scale);\n",
        "\n",
        "    data = [np.array((ee.Array(img.get(col[i])).getInfo())) for i in range(len(col)) if col[i] != 'NDSSI']\n",
        "    if NDSSI:\n",
        "        print(\"calcolo NDSSI\")\n",
        "        b2 = np.array((ee.Array(img.get('B2')).getInfo()))\n",
        "        b8 = np.array((ee.Array(img.get('B8')).getInfo()))\n",
        "        ndssi = (b2 - b8) / (b8 + b2)\n",
        "        data.append(ndssi)\n",
        "\n",
        "    lats = np.array((ee.Array(img.get(\"latitude\")).getInfo()))\n",
        "    lons = np.array((ee.Array(img.get(\"longitude\")).getInfo()))\n",
        "    return lats, lons, data\n",
        "\n",
        "\n",
        "def toImage(lats, lons, data):\n",
        "    # get the unique coordinates\n",
        "    uniqueLats = np.unique(lats)\n",
        "    uniqueLons = np.unique(lons)\n",
        "\n",
        "    # get number of columns and rows from coordinates\n",
        "    ncols = len(uniqueLons)\n",
        "    nrows = len(uniqueLats)\n",
        "\n",
        "    # determine pixelsizes\n",
        "    ys = uniqueLats[1] - uniqueLats[0]\n",
        "    xs = uniqueLons[1] - uniqueLons[0]\n",
        "\n",
        "    # create an array with dimensions of image\n",
        "    arr = np.zeros([nrows, ncols], np.float32)  # -9999\n",
        "\n",
        "    # fill the array with values\n",
        "    counter = 0\n",
        "    for y in range(0, len(arr), 1):\n",
        "        for x in range(0, len(arr[0]), 1):\n",
        "            if lats[counter] == uniqueLats[y] and lons[counter] == uniqueLons[x] and counter < len(data) - 1:\n",
        "                counter += 1\n",
        "                arr[len(uniqueLats) - 1 - y, x] = data[counter]  # we start from lower left corner\n",
        "    return arr\n",
        "\n",
        "def saveDataFrameToGrid(df, xcol, ycol, value_col, n_crs, grid_output):\n",
        "\t#COSTRUISCO IL GRID\n",
        "\trow = df.iloc[0]\n",
        "\trow1 = df.iloc[1]\n",
        "\n",
        "\trowLast = df.iloc[-1]\n",
        "\trowLast1 = df.iloc[-2]\n",
        "\t#NUMERO DI RIGHE E NUMERO DI COLONNE\n",
        "\trows = len(df[ycol].unique())\n",
        "\tcols = len(df[xcol].unique())\n",
        "\tcell_size_y = (df[ycol].max() - df[ycol].min())/rows\n",
        "\tcell_size_x = (df[xcol].max() - df[xcol].min())/cols\n",
        "\tx0, y0 = df[xcol].min() - cell_size_x/2, df[ycol].max()  + cell_size_y/2\n",
        "\tmatrix = np.zeros((rows,cols), dtype=float)\n",
        "\tcount = 0\n",
        "\tdf = df.sort_values([ycol, xcol], ascending= [False, True])\n",
        "\tseries = df[value_col].values\n",
        "\tfor j in range(rows):\n",
        "\t    for i in range(cols):\n",
        "\t        matrix[j,i] = series[count]\n",
        "\t        count+=1\n",
        "\tx1,y1 = x0+cell_size_x*cols, y0 - cell_size_y*rows\n",
        "\tcrs = osr.SpatialReference()\n",
        "\tcrs.ImportFromEPSG(n_crs)\n",
        "\toutput_grid = create_grid_xydiff(x0,x1,y1,y0,cell_size_x, cell_size_y,-9999, crs, grid_output)\n",
        "\toutput_grid[3].WriteArray(matrix,0,0)\n",
        "\n",
        "def create_grid_xydiff(xmin,xmax,ymin,ymax,cell_size_x,cell_size_y, NoData,sourceSR, output):\n",
        "\t#sourceSR = lyr.GetSpatialRef()\n",
        "\t#proj = osr.SpatialReference(wkt=raster.GetProjection())\n",
        "    #crs = osr.SpatialReference()\n",
        "    #crs.ImportFromEPSG(4326)\n",
        "\tcols= round( ((xmax - xmin)/float(cell_size_x)))\n",
        "\trows= round(((ymax - ymin)/float(cell_size_y)))\n",
        "\n",
        "\text= output.split(\".\")[-1]\n",
        "\n",
        "\tif ext == \"tif\":\n",
        "\t\tdriver = gdal.GetDriverByName('GTiff')\n",
        "\telif ext == \"tiff\":\n",
        "\t\tdriver = gdal.GetDriverByName('GTiff')\n",
        "\telif ext == \"flt\":\n",
        "\t\tdriver = gdal.GetDriverByName('EHdr')\n",
        "\telif ext == \"bt\":\n",
        "\t\tdriver = gdal.GetDriverByName('BT')\n",
        "\telse:\n",
        "\t\tprint (\"Definire un formato dell'output valido\")\n",
        "\t\treturn\n",
        "\toutDataset= driver.Create(output,cols,rows,1,GDT_Float32)\n",
        "\tgt= [xmin,cell_size_x,0,ymax,0,-cell_size_y]\n",
        "\toutDataset.SetGeoTransform(gt)\n",
        "\n",
        "\t# dst_wkt= spatialRef.ExportToWkt()\n",
        "\t#\n",
        "\t# outDataset.SetProjection(dst_wkt)\n",
        "\toutband= outDataset.GetRasterBand(1)\n",
        "\toutband.SetNoDataValue(NoData)\n",
        "\t# outRasterSRS = osr.SpatialReference()\n",
        "\t# outRasterSRS.ImportFromEPSG(3003)\n",
        "\toutDataset.SetProjection(sourceSR.ExportToWkt())\n",
        "\tout= [cols,rows,outDataset,outband]\n",
        "\treturn out\n",
        "\n",
        "\n",
        "def ApplyModel3(parametri):\n",
        "    if  not os.path.isdir(os.path.join(parametri['simulations_out'], parametri['date_pred'])):\n",
        "        os.mkdir(os.path.join(parametri['simulations_out'], parametri['date_pred']))\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "    keras.backend.clear_session()\n",
        "    band_request = ['B%s' % i for i in range(1, 13)]\n",
        "    band_request.append('B8A')\n",
        "\n",
        "    NDSSI = False\n",
        "    scale = 50\n",
        "\n",
        "    # print (\"Initialize DONE\")\n",
        "    xMin = parametri['bbox'][0]\n",
        "    xMax = parametri['bbox'][2]\n",
        "    yMin = parametri['bbox'][1]\n",
        "    yMax = parametri['bbox'][3]\n",
        "\n",
        "    area = ee.Geometry.Polygon([[xMin, yMin], \\\n",
        "                                [xMax, yMin], \\\n",
        "                                [xMax, yMax], \\\n",
        "                                [xMin, yMax], \\\n",
        "                                [xMin, yMin]])\n",
        "\n",
        "    addTime = lambda x: x.set('Date', ee.Date(x.get('system:time_start')).format(\"YYYY-MM-dd\"))\n",
        "    collection = ee.ImageCollection(\"COPERNICUS/S2_HARMONIZED\") \\\n",
        "        .filterBounds(area) \\\n",
        "        .select(band_request) \\\n",
        "        .map(addTime) \\\n",
        "        .filter(ee.Filter.inList('Date', ee.List([parametri['date_pred']])))\n",
        "\n",
        "    nImages = collection.size().getInfo()\n",
        "    if nImages == 0: return\n",
        "    imgs = collection.toList(collection.size())\n",
        "    list_imgs = [ee.Image(imgs.get(i)) for i in range(nImages)]\n",
        "\n",
        "    dates_unique = [parametri['date_pred']]\n",
        "    dates_unique.sort()\n",
        "    # check if I have to do a mosaic\n",
        "    list_imgs = []\n",
        "    dates = []\n",
        "    for date in dates_unique:\n",
        "        dates.append(date)\n",
        "        date = ee.Date(date)\n",
        "        filtered = collection.filterDate(date, date.advance(1, 'day'))\n",
        "        image = ee.Image(filtered.mosaic())\n",
        "        list_imgs.append(image)\n",
        "    collection = ee.ImageCollection.fromImages(list_imgs)\n",
        "    # self.nImages = collection.size().getInfo()\n",
        "    valori = []\n",
        "\n",
        "    for i, img in enumerate(list_imgs):\n",
        "        date = dates[i]\n",
        "        lat, lon, data = LatLonImg(img, band_request, area, scale, NDSSI)\n",
        "        break\n",
        "    lats = toImage(lat, lon, lat)\n",
        "    lons = toImage(lat, lon, lon)\n",
        "    index_b4 = band_request.index('B4')\n",
        "    b4_data = toImage(lat, lon, data[index_b4])\n",
        "    index_b2 = band_request.index('B2')\n",
        "    b2_data = toImage(lat, lon, data[index_b2])\n",
        "    index_b3 = band_request.index('B3')\n",
        "    b3_data = toImage(lat, lon, data[index_b3])\n",
        "    index_b8 = band_request.index('B8')\n",
        "    b8_data = toImage(lat, lon, data[index_b8])\n",
        "    model_path = os.path.join(\"./Support\", \"model.h5\")\n",
        "    model_path_json = os.path.join(\"./Support\", \"model.json\")\n",
        "    json_file = open(model_path_json, 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    model = tf.keras.models.model_from_json(loaded_model_json)\n",
        "    model.load_weights(model_path)\n",
        "    dict_bands = {i: toImage(lat, lon, column_band) for i, column_band in enumerate(data)}\n",
        "    nspace = int(parametri['model_setting']['nDim'] / 2)\n",
        "    values_tot = []\n",
        "    lats_effective, lons_effective, b4_values, b2_values, b3_values, b8_values = [], [], [], [], [], []\n",
        "    for nrow in range(lats.shape[0]):\n",
        "        for ncol in range(lats.shape[1]):\n",
        "            values = []\n",
        "            for nband, image in dict_bands.items():\n",
        "                matrix_values = image[nrow - nspace: nrow + nspace + 1, ncol - nspace: ncol + nspace + 1]\n",
        "                if matrix_values.shape != ( parametri['model_setting']['nDim'],  parametri['model_setting']['nDim']):\n",
        "                    break\n",
        "                values.append(matrix_values)\n",
        "            values = np.array(values)\n",
        "            if values.shape == (len(band_request),  parametri['model_setting']['nDim'],  parametri['model_setting']['nDim']):\n",
        "                values_tot.append(values)\n",
        "                lats_effective.append(lats[nrow][ncol])\n",
        "                lons_effective.append(lons[nrow][ncol])\n",
        "                b4_values.append(b4_data[nrow][ncol])\n",
        "                b2_values.append(b2_data[nrow][ncol])\n",
        "                b3_values.append(b3_data[nrow][ncol])\n",
        "                b8_values.append(b8_data[nrow][ncol])\n",
        "    keras.backend.clear_session()\n",
        "    values_tot = np.array(values_tot)\n",
        "    yhat = model.predict(values_tot, verbose=1)\n",
        "    labels_predicted = [np.argmax(perc) for i, perc in enumerate(yhat)]\n",
        "    perc_class0 = [perc[0] for i, perc in enumerate(yhat)]\n",
        "    perc_class1 = [perc[1] for i, perc in enumerate(yhat)]\n",
        "    perc_class2 = [perc[2] for i, perc in enumerate(yhat)]\n",
        "    dfRes = pd.DataFrame()\n",
        "    dfRes['x'] = lons_effective\n",
        "    dfRes['y'] = lats_effective\n",
        "    dfRes['value'] = labels_predicted\n",
        "    dfRes['perc_class0'] = perc_class0\n",
        "    dfRes['perc_class1'] = perc_class1\n",
        "    dfRes['perc_class2'] = perc_class2\n",
        "    dfRes['value_b4'] = b4_values\n",
        "    dfRes['value_b2'] = b2_values\n",
        "    dfRes['value_b3'] = b3_values\n",
        "    dfRes['value_b8'] = b8_values\n",
        "    dfRes.loc[dfRes['value'] == 2,'b4_mask'] = dfRes['value_b4']\n",
        "    dfRes.loc[dfRes['value'] == 0,'b4_mask'] = 0\n",
        "    dfRes.loc[dfRes['value'] == 2, 'b2_mask'] = dfRes['value_b2']\n",
        "    dfRes.loc[dfRes['value'] == 0, 'b2_mask'] = 0\n",
        "    dfRes.loc[dfRes['value'] == 2, 'b3_mask'] = dfRes['value_b3']\n",
        "    dfRes.loc[dfRes['value'] == 0, 'b3_mask'] = 0\n",
        "    dfRes.loc[dfRes['value'] == 2, 'b8_mask'] = dfRes['value_b8']\n",
        "    dfRes.loc[dfRes['value'] == 0, 'b8_mask'] = 0\n",
        "    dfRes['perc_class'] = dfRes['value_b4'] * dfRes['perc_class1']\n",
        "    try:\n",
        "        os.mkdir(os.path.join(parametri['simulations_out'],parametri['date_pred']))\n",
        "    except: pass\n",
        "    saveDataFrameToGrid(dfRes, 'x', 'y', 'b4_mask', 4326, os.path.join(parametri['simulations_out'],parametri['date_pred'], \"b4_mask.tif\" ))\n",
        "    saveDataFrameToGrid(dfRes, 'x', 'y', 'b2_mask', 4326, os.path.join(parametri['simulations_out'],parametri['date_pred'], \"b2_mask.tif\" ))\n",
        "    saveDataFrameToGrid(dfRes, 'x', 'y', 'b3_mask', 4326, os.path.join(parametri['simulations_out'],parametri['date_pred'], \"b3_mask.tif\" ))\n",
        "    saveDataFrameToGrid(dfRes, 'x', 'y', 'b8_mask', 4326, os.path.join(parametri['simulations_out'],parametri['date_pred'], \"b8_mask.tif\" ))\n",
        "    saveDataFrameToGrid(dfRes, 'x', 'y', 'value', 4326, os.path.join(parametri['simulations_out'],parametri['date_pred'], \"mask.tif\" ))\n",
        "    saveDataFrameToGrid(dfRes, 'x', 'y', 'value_b4', 4326, os.path.join(parametri['simulations_out'],parametri['date_pred'], \"b4_value.tif\" ))\n",
        "    saveDataFrameToGrid(dfRes, 'x', 'y', 'value_b2', 4326, os.path.join(parametri['simulations_out'],parametri['date_pred'], \"b2_value.tif\" ))\n",
        "    saveDataFrameToGrid(dfRes, 'x', 'y', 'value_b3', 4326, os.path.join(parametri['simulations_out'],parametri['date_pred'], \"b3_value.tif\" ))\n",
        "    saveDataFrameToGrid(dfRes, 'x', 'y', 'value_b8', 4326, os.path.join(parametri['simulations_out'],parametri['date_pred'], \"b8_value.tif\" ))\n",
        "    saveDataFrameToGrid(dfRes, 'x', 'y', 'perc_class', 4326, os.path.join(parametri['simulations_out'],parametri['date_pred'], \"value_perc.tif\" ))\n",
        "    saveDataFrameToGrid(dfRes, 'x', 'y', 'perc_class0', 4326, os.path.join(parametri['simulations_out'],parametri['date_pred'], \"perc_class0.tif\" ))\n",
        "    saveDataFrameToGrid(dfRes, 'x', 'y', 'perc_class1', 4326, os.path.join(parametri['simulations_out'],parametri['date_pred'], \"perc_class1.tif\" ))\n",
        "    saveDataFrameToGrid(dfRes, 'x', 'y', 'value', 4326, os.path.join(parametri['simulations_out'],parametri['date_pred'], \"classification.tif\" ))\n",
        "\n",
        "    del values_tot\n",
        "    del dfRes\n",
        "    del lats_effective, lons_effective, b4_values\n",
        "    del lats, lons\n",
        "    del data\n",
        "    del yhat, labels_predicted, collection\n",
        "    del model,\n",
        "    keras.backend.clear_session()\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "QrA9lWDWAqkp",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Select the grid\n",
        "\n",
        "Execute the code and from the generated select box chose the id of the rectangle of the grid that you want use."
      ],
      "metadata": {
        "id": "dEws_w9WrwIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Execute the Step 3 - Select from the Grid\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "dfGrid = gp.read_file(\"./Support/grid.shp\")\n",
        "\n",
        "\n",
        "\n",
        "# Crea il grafico\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "dfGrid.plot(ax=ax, color='blue', edgecolor='black')\n",
        "dfGrid['centroid'] = dfGrid.geometry.centroid\n",
        "\n",
        "# Aggiungi le etichette al centro dei poligoni\n",
        "for x, y, label in zip(dfGrid.centroid.x, dfGrid.centroid.y, dfGrid['id']):\n",
        "    ax.text(x, y, label, fontsize=10, ha='center', va='center')\n",
        "\n",
        "\n",
        "values = dfGrid.id.values\n",
        "\n",
        "select = widgets.Dropdown(\n",
        "    options=values,\n",
        "    value=values[0],\n",
        "    description='ID Grid',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "select"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JIdy8mp66NBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Select the dates and run the analyses images\n",
        "\n",
        "Select the temporal period and execute the analysis of the images. The results are saved in in \"Simulations\" folder."
      ],
      "metadata": {
        "id": "JI51PdLAsHgx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPib9hvO8Pmb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Execute the Step 4 - Apply the model\n",
        "\n",
        "parametri = {}\n",
        "id =select.value\n",
        "\n",
        "geom = dfGrid[dfGrid.id == id].geometry.values[0]\n",
        "bbox = geom.bounds\n",
        "parametri['bbox'] = bbox\n",
        "simulations_out = os.path.join('Simulations', str(id))\n",
        "try:\n",
        "  os.makedirs(simulations_out)\n",
        "except: pass\n",
        "parametri['simulations_out'] = simulations_out\n",
        "parametri['model_setting'] = {\"nNodi\": 2 ** 5,'patience': 200,'nDim': 11}\n",
        "date_start = '2018-03-22' # @param {type:\"date\"}\n",
        "date_end = '2018-04-22' # @param {type:\"date\"}\n",
        "\n",
        "date = date_start\n",
        "i = 0\n",
        "while date < date_end:\n",
        "    date = pd.to_datetime(date_start) + pd.Timedelta(days=i)\n",
        "    date = date.strftime('%Y-%m-%d')\n",
        "    print (date)\n",
        "    parametri['date_pred'] = date\n",
        "    parametri['grid_number_execute'] = id\n",
        "    ApplyModel3(parametri)\n",
        "    tf.keras.backend.clear_session()\n",
        "    keras.backend.clear_session()\n",
        "    if len(os.listdir(os.path.join(parametri['simulations_out'],parametri['date_pred']))) == 0:\n",
        "      os.rmdir(os.path.join(parametri['simulations_out'],parametri['date_pred']))\n",
        "    i += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Create the zip file to export the results"
      ],
      "metadata": {
        "id": "M2Aggm1yspo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Execute the Step 5 - Export Simulations folder\n",
        "import shutil\n",
        "shutil.make_archive(\"Simulations\", 'zip', \"./Simulations\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "j1UrMkJrFcer"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}